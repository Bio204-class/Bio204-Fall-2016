---
title: "Introduction to Confidence Intervals"
author: "Paul M. Magwene"
date: "October 24, 2016"
output:
  html_document:
    fig_height: 3
    fig_width: 5
    highlight: default
    theme: readable
    toc: yes
    toc_depth: '2'
  html_notebook:
    highlight: default
    theme: readable
    toc: yes
    toc_depth: 2
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, prompt = FALSE, eval = TRUE, 
                      comment=NA, warning = FALSE, results="markup",
                      message = FALSE, cache = FALSE)
options(digits = 4)
```



# Standard Error of the Mean Revisted

Let's return to a concept we covered in the last lecture -- the standard error of the mean.

Here was the scenario we explored: 

1. You want to learn about a variable  $X$ in a population of interest.

2. Assume $X$ is normally distributed with mean $\mu$ and standard deviation $\sigma$ ($X \sim N(\mu,\sigma)$).
 
3. You take a random sample of size $n$ from the population and estimate the sample mean, $\overline{x}$.

4. You repeat step 3 a large number of times, calculating a new sample mean each time.

5. We call the *distribution of sample means* the **sampling distribution of the mean** (remember that you can  estimate the sampling distribution for any statistic of interest).

6. You examine the spread of your sample means. You will find that the sampling distribution of the mean is approximately normally distributed with mean $\sim μ$, and with a standard deviation $\sim \frac{\sigma}{\sqrt{n}}$.
\[
\overline{x} \sim N \left( \mu, \frac{\sigma}{\sqrt{n}}\ \right)
\]
 
We refer to the standard deviation of a sampling distibution of a statistic as the **standard error** of that statistic. When the statistic of interest is the mean, this is the **standard error of the mean** (standard errors of the mean are often just referred to as "standard errors" as this is the most common standard error one usually calculates).

```{r}
library(ggplot2)
set.seed(20161024)
```

# Simulating the sample distribution of the mean

Simulate generation of samples and estimation of sampling distribution.
```{r}
mu <- 10
sigma <- 2

sampling.distn.of.mean <- function(mean = 0, sd = 1, size = 25, nreps = 1000) {
  sample.means <- rep(NA, nreps)
  for(i in 1:nreps) {
    sample.n <- rnorm(size, mean = mean, sd = sd)
    sample.means[i] = mean(sample.n)  
  }
  return(sample.means)
}

sdist.25 <- sampling.distn.of.mean(mu, sigma, size = 25)
se.25 <- sd(sdist.25)
sdist.50 <- sampling.distn.of.mean(mu, sigma, size = 50)
se.50 <- sd(sdist.50)
sdist.100 <- sampling.distn.of.mean(mu, sigma, size = 100)
se.100 <- sd(sdist.100)
sdist.200 <- sampling.distn.of.mean(mu, sigma, size = 200)
se.200 <- sd(sdist.200)
sdist.400 <- sampling.distn.of.mean(mu, sigma, size = 400)
se.400 <- sd(sdist.400)
```

Then generate some plots:
```{r, fig.width = 10}
a <- ggplot() + 
  geom_histogram(aes(x = sdist.25)) + 
  geom_histogram(aes(x = sdist.50), fill = "steelblue", alpha = 0.65) + 
  geom_histogram(aes(x = sdist.100), fill = "firebrick", alpha = 0.65) + 
  geom_histogram(aes(x = sdist.200), fill = "chocolate", alpha = 0.65) + 
  geom_histogram(aes(x = sdist.400), fill = "gold", alpha = 0.65) + 
  labs(x = "Sample Size", y = "Count")

theory <- sapply(seq(10,500,10), function(x){ sigma/sqrt(x) })

b <- ggplot() + 
  geom_point(aes(x = c(25,50,100,200,400), 
                 y = c(se.25, se.50, se.100, se.200, se.400))) + 
  geom_line(aes(x = seq(10,500,10), y = theory), color="red") +
  labs(x = "Sample size", y = "Std Error of Mean") 

library(cowplot)
plot_grid(a,b)
```

 
# Sample Estimate of the Standard Error of the Mean

In real-life life, we don't have access to the sampling distribution of the mean or the true population parameter $\sigma$ from which can calculate the standard error of the mean. However, we can still use our unbiased sample estimator of the standard deviation, $s$, to estimate the standard error of the mean.

\[
{SE}_{\overline{x}} = \frac{s}{\sqrt{n}}
\]

## Conditions for sampling distribution to be nearly normal

For the sampling distribution of the mean to be nearly normal with ${SE}_\overline{x}$ accurate, the following conditions should hold:

* Sample observations are independent
* Sample size is large  ($n \geq 30$ is good rule of thumb)
* Population distribution is not strongly skewed


# Confidence Intervals for the Mean

We know that given a random sample from a population of interest, the mean of $X$ in our random sample is unlikely to be the true population mean of $X$.  However, our simulations have taught us a number of things:

1. As  sample size increases, the sample estimate of the mean is more likely to be close to the true mean
2. As sample size increases, the standard deviation of the sampling distribution of the mean (= standard error of the mean) decreases

We can use this knowledge to calculate _plausible ranges of values_ for the mean.  We call such ranges **confidence intervals** for the mean (the idea of confidence intervals can apply to other statistics as well). We're going to express our confidence intervals in terms of multiples of the standard error. 

# Simulating confidence intervals

Let's start by using simulation to explore how often our confidence intervals capture the true mean when we base our confidence intervals on different multiples, $z$, of the SE.

\[
{CI}_\overline{x}  = \overline{x} \pm  (z \times {SE}_\overline{x})
\]

For the purposes of this simulation, let's consider samples of size 50, drawn from the same population of interest as before. We're going to generate a large number of such samples, and for each sample we will calculate the CI of the mean using the formula above.  We will then ask, "for what fraction of the samples did our CI overlap the true population mean"?  This will give us a sense of how well different confidence intervals do in providing a plausible range for the true mean.

```{r}
N = 1000

# genereate N random samples of size 50, with mean and std dev given by mu and sigma
# as defined previously.  `replicate` returns a matrix of dim (1000,50), where each 
# column of the the matrix corresponds to a sample
samples.50 <- replicate(N, rnorm(50, mean = mu, sd = sigma))

# calculate means by samples (columns)
means.50 <- apply(samples.50, 2, mean)

# calculates std devs for each sample (columns)
sd.50 <- apply(samples.50, 2, sd)

# calculate sample standard errors for each sample
se.50 <- sd.50/sqrt(50)

frac.overlap.true.mean <- c()
zs <- seq(1,3,0.05)
for (z in zs) {
  low.ci <- means.50 - z*se.50
  high.ci <- means.50 + z*se.50
  overlap.mu <- (low.ci <= mu) & (high.ci >= mu)
  frac <- length(which(overlap.mu))/N
  frac.overlap.true.mean <- c(frac.overlap.true.mean, frac)
}

theory.frac.overlap <- 1 - 2*(1 - pnorm(zs))

qplot(x = zs, y = frac.overlap.true.mean, geom = "line") +
  geom_line(aes(x = zs, y = theory.frac.overlap), color="red") + 
  labs(x = "z in CI =  sample mean ± z × SE",
       y = "% of CI that include \ntrue population mean")

  
```

## Interpreting our simulation

How should we interpret the results above?  We found as we increased the scaling of our confidence intervals (larger $z$), the true mean was within sample confidence intervals a greater proportion of the time. For example, when $z = 1$ we found that the true mean was within our CIs roughly 67% of the time, while at $z = 2$ the true mean was within our confidence intervals approximately 95% of the time.

We call $x \pm 2 \times {SE}_\overline{x}$ the approximate 95% confidence interval of the mean (see below for exact values of z). Given such a CI calculated from a random sample we can say we are "95% confident" that we have captured the true mean within the bounds of the CI (subject to the caveats about the sampling distribution above).  By this we mean if we took many samples and built a confidence interval from each sample using the equation above, then about 95% of those intervals would contain the actual mean, μ. Note that this is exactly what we did in our simulation!


```{r, fig.height = 6, fig.width = 3}
ndraw <- 100
x <- means.50[1:ndraw]
y <- seq(1,ndraw)
xerr <- 1.96*se.50[1:ndraw]

qplot(x = x, y = y) + 
  geom_errorbarh(aes(xmax = x + 1.96 * se.50[1:ndraw], 
                     xmin = x - 1.96 * se.50[1:ndraw])) +
  geom_vline(xintercept = mu, color = "red", linetype = "dashed", size = 1) + 
  labs(x = "mean x and estimated CI", y = "sample", 
       title = "95% CI: mean ± 1.96×SE\nfor 100 samples of size 50")

```

## Generating a table of CIs and corresponding margins of error

The table below gives the percent CI and the corresponding **margin of error** (the appropriate $z$ to use in $z \times {SE}$) for that confidence interval.

```{r}
percent <- c(0.80, 0.90, 0.95, 0.99, 0.997)
zval <- -qnorm((1 - percent)/2) # account for two tails of the sampling distn

z.df <- data.frame(ci.percent = percent, margin.of.error = zval)
z.df
```

# Interpretting Confidence Intervals

You should be careful in interpretting confidence intervals. This quote from the [NIST page on confidence intervals](http://www.itl.nist.gov/div898/handbook/eda/section3/eda352.htm) provides a useful explanation:

> As a technical note, a 95 % confidence interval does not mean that there is a 95 % probability that the interval contains the true mean. The interval computed from a given sample either contains the true mean or it does not. Instead, the level of confidence is associated with the method of calculating the interval. The confidence coefficient is simply the proportion of samples of a given size that may be expected to contain the true mean. That is, for a 95 % confidence interval, if many samples are collected and the confidence interval computed, in the long run about 95 % of these intervals would contain the true mean.

That is, "the 95% probability relates to the reliability of the estimation procedure, not to a specific calculated interval" ([Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval)).

We can think of the CI for the mean as an estimate of plausible values for the population mean, based on the observed sample.